import { NextResponse } from "next/server"
import { put } from "@vercel/blob"
import { v4 as uuidv4 } from "uuid"
import fs from "fs/promises"
import { detectEnvironment } from "@/lib/environment-detector"
import { PlaywrightRecorder } from "@/lib/playwright-recorder"
import { generateActionsFromAI } from "@/lib/ai-action-generator"
import { getTestVideoUrls, generateColorfulThumbnail } from "@/lib/video-generator"
import { createServerClient } from '@supabase/ssr'
import { createGenerationHistory } from '@/lib/generation-history'
import { cookies } from "next/headers"

// ä¸´æ—¶æ–¹æ¡ˆ
type Database = any

interface GenerateVideoRequest {
  mode: "url-only" | "url-prompt" | "code-aware"
  url: string
  task: string
  workflow?: string
  elements?: string
  github?: string
  aspectRatio?: string
}

export async function POST(request: Request) {
  const startTime = Date.now()
  const MAX_EXECUTION_TIME = 55000 // 55ç§’ï¼Œç•™5ç§’ç¼“å†²

  const recorder: PlaywrightRecorder | null = null
  let tempDir: string | null = null

  try {
    console.log("ğŸ“ Starting AI-powered video generation...")

    const body: GenerateVideoRequest = await request.json()
    console.log("ğŸ“ Request data:", body)

    // éªŒè¯å¿…è¦çš„å‚æ•°
    if (!body.url || !body.task) {
      return NextResponse.json(
        {
          success: false,
          error: "Missing required parameters: url and task",
        },
        { status: 400 },
      )
    }

    // éªŒè¯URLæ ¼å¼
    try {
      new URL(body.url)
    } catch {
      return NextResponse.json(
        {
          success: false,
          error: "Invalid URL format",
        },
        { status: 400 },
      )
    }

    // æ£€æµ‹ç¯å¢ƒèƒ½åŠ›
    const capabilities = await detectEnvironment()
    console.log("ğŸ” Environment capabilities:", capabilities)

    // åˆ›å»ºä¸´æ—¶ç›®å½•
    tempDir = `/tmp/videos/${uuidv4()}`
    await fs.mkdir(tempDir, { recursive: true })

    if (capabilities.canRecord && !capabilities.isVercel) {
      // çœŸå®å½•åˆ¶æ¨¡å¼
      console.log("ğŸ¬ Using AI-powered real recording...")
      const result = await performAIRecording(
        body,
        capabilities,
        tempDir,
        MAX_EXECUTION_TIME - (Date.now() - startTime),
      )
      return NextResponse.json({ success: true, data: result })
    } else {
      // æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼ - ä»ç„¶ä½¿ç”¨AIç”Ÿæˆæ­¥éª¤ï¼Œä½†ä¸è¿›è¡ŒçœŸå®å½•åˆ¶
      console.log("ğŸ­ Using AI-powered simulation...")
      const result = await performAISimulation(body)
      return NextResponse.json({ success: true, data: result })
    }
  } catch (error) {
    console.error("âŒ Video generation error:", error)

    let errorMessage = "è§†é¢‘ç”Ÿæˆå¤±è´¥"
    if (error instanceof Error) {
      if (error.message.includes("timeout") || error.message.includes("time")) {
        errorMessage = "å¤„ç†è¶…æ—¶ï¼Œè¯·å°è¯•æ›´ç®€å•çš„ä»»åŠ¡æˆ–ç¨åé‡è¯•"
      } else if (error.message.includes("net::ERR_NAME_NOT_RESOLVED")) {
        errorMessage = "æ— æ³•è®¿é—®æŒ‡å®šçš„ç½‘ç«™ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®"
      } else if (error.message.includes("Navigation failed")) {
        errorMessage = "é¡µé¢å¯¼èˆªå¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç«™é™åˆ¶äº†è‡ªåŠ¨åŒ–è®¿é—®"
      } else {
        errorMessage = error.message
      }
    }

    return NextResponse.json(
      {
        success: false,
        error: errorMessage,
        details: process.env.NODE_ENV === "development" ? error : undefined,
      },
      { status: 500 },
    )
  }
}

async function performAIRecording(
  body: GenerateVideoRequest,
  capabilities: any,
  tempDir: string,
  maxTime: number,
): Promise<any> {
  let recorder: PlaywrightRecorder | null = null
  const startTime = Date.now()

  try {
    console.log("ğŸ¤– Starting AI-powered recording for:", body.url)

    // åˆå§‹åŒ–å½•åˆ¶å™¨
    const viewport = getViewportFromAspectRatio(body.aspectRatio || "16:9")
    recorder = new PlaywrightRecorder(capabilities)
    await recorder.initialize({
      url: body.url,
      viewport,
      outputDir: tempDir,
      timeout: Math.min(20000, maxTime * 0.4),
    })

    // å¯¼èˆªåˆ°ç›®æ ‡ç½‘ç«™
    console.log("ğŸŒ Navigating to target website...")
    await recorder.navigateToUrl(body.url)

    // åˆ†æé¡µé¢ç»“æ„
    console.log("ğŸ” Analyzing page structure...")
    const pageAnalysis = await recorder.analyzePage()
    console.log("ğŸ“Š Page analysis result:", pageAnalysis)

    // ä½¿ç”¨AIç”Ÿæˆæ™ºèƒ½äº¤äº’æ­¥éª¤
    console.log("ğŸ¤– Generating AI-powered actions...")
    const aiActions = await generateActionsFromAI(
      body.url,
      body.task,
      body.mode,
      pageAnalysis,
      body.workflow,
      body.elements,
      body.github,
    )

    console.log(
      "âœ… Generated",
      aiActions.length,
      "AI actions:",
      aiActions.map((a) => a.description),
    )

    // æ‰§è¡ŒAIç”Ÿæˆçš„äº¤äº’æ­¥éª¤
    console.log("ğŸ­ Executing AI-generated actions...")
    await recorder.executeActions(aiActions)

    // è·å–å½•åˆ¶çš„è§†é¢‘
    const rawVideoPath = await recorder.close()

    if (!rawVideoPath) {
      throw new Error("Failed to get recorded video")
    }

    // ä¸Šä¼ è§†é¢‘åˆ°Blobå­˜å‚¨
    const videoId = uuidv4()
    const videoBuffer = await fs.readFile(rawVideoPath)

    const { url: videoUrl } = await put(`video/${videoId}.webm`, videoBuffer, {
      access: "public",
      contentType: "video/webm",
    })

    // ç”Ÿæˆç¼©ç•¥å›¾
    const thumbnailData = generateColorfulThumbnail(`${body.task} - AI Recording`)
    const { url: thumbnailUrl } = await put(`thumbnails/${videoId}.jpg`, thumbnailData, {
      access: "public",
      contentType: "image/jpeg",
    })

    // ä¿å­˜åˆ°å†å²è®°å½•
    const supabase = createServerClient<Database>(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      { cookies: cookies as any }
    )
    const { data: { user } } = await supabase.auth.getUser()
    
    if (user) {
      await createGenerationHistory({
        video_url: videoUrl,
        video_name: `${body.task} - AI Recording`,
        video_size: videoBuffer.length,
        video_duration: 30000, // 30ç§’
        video_format: "webm",
        video_resolution: `${viewport.width}x${viewport.height}`,
        status: "completed"
      })
    }

    return {
      videoUrl,
      thumbnailUrl,
      duration: "00:30",
      resolution: `${viewport.width}x${viewport.height}`,
      size: `${Math.round((videoBuffer.length / 1024 / 1024) * 10) / 10} MB`,
      format: "WebM",
      createdAt: new Date().toISOString(),
      steps: aiActions.map((action) => action.description),
      aiReasoning: aiActions.map((action) => action.reasoning),
      mode: body.mode,
      task: body.task,
      url: body.url,
      recordingType: "ai_real_recording",
      pageAnalysis: {
        title: pageAnalysis.title,
        elementsFound: pageAnalysis.elements
          ? {
              buttons: pageAnalysis.elements.buttons?.length || 0,
              inputs: pageAnalysis.elements.inputs?.length || 0,
              links: pageAnalysis.elements.links?.length || 0,
              forms: pageAnalysis.elements.forms?.length || 0,
            }
          : {},
      },
    }
  } catch (error) {
    console.log("AI recording failed, falling back to simulation:", error)
    return performAISimulation(body)
  }
}

async function performAISimulation(body: GenerateVideoRequest): Promise<any> {
  console.log("ğŸ­ Performing AI-powered simulation...")

  try {
    // å³ä½¿æ˜¯æ¨¡æ‹Ÿï¼Œä¹Ÿä½¿ç”¨AIç”ŸæˆçœŸå®çš„æ­¥éª¤
    console.log("ğŸ¤– Generating AI actions for simulation...")

    // æ¨¡æ‹Ÿé¡µé¢åˆ†æç»“æœ
    const mockPageAnalysis = {
      title: `${body.url} - AI Analysis`,
      url: body.url,
      elements: {
        buttons: [
          { text: "Submit", id: "submit-btn", className: "btn btn-primary", visible: true },
          { text: "Cancel", id: "cancel-btn", className: "btn btn-secondary", visible: true },
        ],
        inputs: [
          { type: "text", placeholder: "Enter your name", name: "name", visible: true },
          { type: "email", placeholder: "Enter your email", name: "email", visible: true },
        ],
        links: [
          { text: "Home", href: "/", visible: true },
          { text: "About", href: "/about", visible: true },
        ],
        forms: [{ id: "main-form", className: "form", action: "/submit", method: "POST" }],
      },
    }

    const aiActions = await generateActionsFromAI(
      body.url,
      body.task,
      body.mode,
      mockPageAnalysis,
      body.workflow,
      body.elements,
      body.github,
    )

    console.log(
      "âœ… Generated AI simulation steps:",
      aiActions.map((a) => a.description),
    )

    // ä½¿ç”¨ä¸€ä¸ªç›¸å…³çš„æµ‹è¯•è§†é¢‘è€Œä¸æ˜¯éšæœºé€‰æ‹©
    const testVideoUrls = getTestVideoUrls()
    const selectedVideoUrl = testVideoUrls[0] // ä½¿ç”¨ç¬¬ä¸€ä¸ªä½œä¸ºé»˜è®¤

    // ç”Ÿæˆç¼©ç•¥å›¾
    const videoId = uuidv4()
    const thumbnailData = generateColorfulThumbnail(`${body.task} - AI Simulation`)

    const { url: thumbnailUrl } = await put(`thumbnails/${videoId}.jpg`, thumbnailData, {
      access: "public",
      contentType: "image/jpeg",
    })

    // ä¿å­˜åˆ°å†å²è®°å½•
    const supabase = createServerClient<Database>(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      { cookies: cookies as any }
    )
    const { data: { user } } = await supabase.auth.getUser()
    
    if (user) {
      await createGenerationHistory({
        video_url: selectedVideoUrl,
        video_name: `${body.task} - AI Simulation`,
        video_size: 2200000, // 2.1 MB
        video_duration: 30000, // 30ç§’
        video_format: "mp4",
        video_resolution: getResolutionFromAspectRatio(body.aspectRatio || "16:9"),
        status: "completed"
      })
    }

    return {
      videoUrl: selectedVideoUrl,
      thumbnailUrl,
      duration: "00:30",
      resolution: getResolutionFromAspectRatio(body.aspectRatio || "16:9"),
      size: "2.1 MB",
      format: "MP4",
      createdAt: new Date().toISOString(),
      steps: aiActions.map((action) => action.description),
      aiReasoning: aiActions.map((action) => action.reasoning),
      mode: body.mode,
      task: body.task,
      url: body.url,
      recordingType: "ai_simulation",
      simulationNote: "è¿™æ˜¯åŸºäºAIåˆ†æç”Ÿæˆçš„æ¨¡æ‹Ÿæ¼”ç¤ºã€‚åœ¨æ”¯æŒPlaywrightçš„ç¯å¢ƒä¸­ï¼Œå°†è¿›è¡ŒçœŸå®å½•åˆ¶ã€‚",
      pageAnalysis: {
        title: mockPageAnalysis.title,
        elementsFound: {
          buttons: mockPageAnalysis.elements.buttons.length,
          inputs: mockPageAnalysis.elements.inputs.length,
          links: mockPageAnalysis.elements.links.length,
          forms: mockPageAnalysis.elements.forms.length,
        },
      },
    }
  } catch (error) {
    console.error("AI simulation failed:", error)

    // æœ€åçš„fallback
    const videoId = uuidv4()
    const thumbnailData = generateColorfulThumbnail("Basic Demo")
    const { url: thumbnailUrl } = await put(`thumbnails/${videoId}.jpg`, thumbnailData, {
      access: "public",
      contentType: "image/jpeg",
    })

    // ä¿å­˜åˆ°å†å²è®°å½•
    const supabase = createServerClient<Database>(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      { cookies: cookies as any }
    )
    const { data: { user } } = await supabase.auth.getUser()
    
    if (user) {
      await createGenerationHistory({
        video_url: getTestVideoUrls()[0],
        video_name: `${body.task} - Basic Demo`,
        video_size: 2200000, // 2.1 MB
        video_duration: 30000, // 30ç§’
        video_format: "mp4",
        video_resolution: getResolutionFromAspectRatio(body.aspectRatio || "16:9"),
        status: "completed"
      })
    }

    return {
      videoUrl: getTestVideoUrls()[0],
      thumbnailUrl,
      duration: "00:30",
      resolution: getResolutionFromAspectRatio(body.aspectRatio || "16:9"),
      size: "2.1 MB",
      format: "MP4",
      createdAt: new Date().toISOString(),
      steps: ["åŸºç¡€é¡µé¢åŠ è½½", "ç®€å•äº¤äº’æ¼”ç¤º", "å®Œæˆå½•åˆ¶"],
      mode: body.mode,
      task: body.task,
      url: body.url,
      recordingType: "basic_demo",
    }
  }
}

function getViewportFromAspectRatio(aspectRatio: string): { width: number; height: number } {
  const viewports: Record<string, { width: number; height: number }> = {
    "16:9": { width: 1280, height: 720 },
    "4:3": { width: 1024, height: 768 },
    "1:1": { width: 1080, height: 1080 },
    "9:16": { width: 720, height: 1280 },
    "21:9": { width: 1280, height: 548 },
  }
  return viewports[aspectRatio] || { width: 1280, height: 720 }
}

function getResolutionFromAspectRatio(aspectRatio: string): string {
  const viewport = getViewportFromAspectRatio(aspectRatio)
  return `${viewport.width}x${viewport.height}`
}
